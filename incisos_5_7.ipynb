{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inciso 5: Analice los resultados del modelo de regresión ¿Qué tan bien le fue prediciendo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Por lo general esto se vería como que es bueno prediciendo los datos aunque puede haber cierto caso de overfitting. En caso se tengan datos nuevos, estos puede que no vayan a poder ser tan bien predecidos como se debería esperar. Sin embargo, por el momento como predictor de precios en el area que se esta trabajando si sirve como un buen modelo de regresión y nos provee una buena medida para predecir los precios de las casas. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inciso 6: Compare los resultados con el modelo de regresión lineal y el arbol de regresión que hizo en las hojas pasadas, ¿Cuál funcionó mejor?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando con el modelo de clasificación  (arbol de regresión) que se tuvo una precisión del 0.72 aproximadamente, este modelo de regresión naive bayes cuenta con una precisión de 0.96. Incluso si se comapra con el modelo de regresión lineal, este modelo de regresión naive excede las expectativas ya que el modelo de regresión lineal solo llego a un 0.65 de efectividad en cuanto a sus predicciones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inciso 7: Haga un análisis de la eficiencia del modelo de clasificación utilizando una matriz de confusión. Tenga en cuenta le efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "datos = pd.read_csv(\"train.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las variables numéricas relevantes\n",
    "numericas = datos.select_dtypes(include='number')\n",
    "numericas = numericas.drop([\"Fireplaces\", \"GarageYrBlt\", \"Id\", \"MSSubClass\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\", \"ScreenPorch\", \"MoSold\", \"YrSold\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermedias    490\n",
      "Económicas     487\n",
      "Caras          483\n",
      "Name: Clase, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Crear variable respuesta que clasifica las casas en Económicas, Intermedias o Caras\n",
    "terciles = np.percentile(numericas[\"SalePrice\"], [33.33, 66.67])\n",
    "limite_economicas = terciles[0]\n",
    "limite_caras = terciles[1]\n",
    "numericas[\"Clase\"] = pd.cut(numericas[\"SalePrice\"], bins=[0, limite_economicas, limite_caras, float(\"inf\")], labels=[\"Económicas\", \"Intermedias\", \"Caras\"])\n",
    "\n",
    "# Mostrar clasificación de las casas\n",
    "print(numericas[\"Clase\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericas = numericas.dropna()\n",
    "X = numericas.drop(\"Clase\", axis=1)\n",
    "y = numericas[\"Clase\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alien Ware\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79,  0,  4],\n",
       "       [ 0, 82,  2],\n",
       "       [ 1,  1, 70]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "tp = confusion_matrix(y_test, y_pred)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision económicas:  0.9518072289156626\n",
      "Precision intermedias:  0.9761904761904762\n",
      "Precision caras:  0.9722222222222222\n",
      " \n",
      "Recall económicas:  0.9875\n",
      "Recall intermedias:  0.9879518072289156\n",
      "recall caras:  0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision económicas: \", (tp[0][0]/tp[0].sum()))\n",
    "print(\"Precision intermedias: \", (tp[1][1]/tp[1].sum()))\n",
    "print(\"Precision caras: \", (tp[2][2]/tp[2].sum()))\n",
    "print(\" \")\n",
    "print(\"Recall económicas: \", (tp[:, 0][0]/tp[:,0].sum()))\n",
    "print(\"Recall intermedias: \", (tp[:,1][1]/tp[:,1].sum()))\n",
    "print(\"Recall caras: \", (tp[:,2][2]/tp[:,2].sum()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en la matriz de confusión se tiene al clasificar todas las casas se tuvo una precisión del 0.96 en promedio. Lo cual nos dice que por lo general hay una buena clasificación de los datos y que además los datos estan balanceados y por ello no hay tantos errores. Sin embargo, cuando se observa el recall de las caras hay una leve disminucioón aunque no es muy significativa ya que aun proporciona un 0.92 de recall. \n",
    "\n",
    "Estos valores en donde se equivocaron las predicciones puede deberse a que el precio estaba entre un punto intermedio entre las 3 opciones y por lo tanto por sus distintas características, no pudo predecir correctamente su categoría. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
